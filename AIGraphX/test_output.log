/home/thezfz/miniconda/envs/AIGraphX/lib/python3.11/site-packages/pytest_asyncio/plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
============================= test session starts ==============================
platform linux -- Python 3.11.12, pytest-8.3.5, pluggy-1.5.0 -- /home/thezfz/miniconda/envs/AIGraphX/bin/python
cachedir: .pytest_cache
rootdir: /home/thezfz/MVP/AIGraphX
plugins: asyncio-0.26.0, anyio-4.9.0, cov-6.1.1, mock-3.14.0
asyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collecting ... collected 1 item

tests/scripts/test_sync_pg_to_neo4j.py::test_run_sync_success_direct_mocks 
DEBUG: Calling run_sync...
DEBUG: SYNC fetch_side_effect received call. Query: 'SELECT * FROM hf_models;...', Batch: 10, Params: None
DEBUG: Mock PG _async_generator yielding 3 items for query: SELECT * FROM hf_models;...
DEBUG: Mock PG _async_generator finished yielding for query: SELECT * FROM hf_models;...
DEBUG: SYNC fetch_side_effect received call. Query: '
        SELECT
            p.paper_id, p.pwc_id, p.arxiv_id_base, p.arxiv_id_versioned, p.title,
  ...', Batch: 10, Params: None
DEBUG: WARNING - Unmatched query in sync mock fetch: 
        SELECT
            p.paper_id, p.pwc_id, p.arxiv_id_base, p.arxiv_id_versioned, p.title,
            p.authors, p.summary, p.published_date, p.area, p.pwc_url,
            p.pdf_url, p.doi, p.primary_category, p.categories
        FROM papers p
    
DEBUG: Mock PG _async_generator yielding 0 items for query: 
        SELECT
            p.paper_id, p.pwc_id, p.arxiv_id_base, p.arxiv_id_versioned, p.title,
  ...
DEBUG: Mock PG _async_generator finished yielding for query: 
        SELECT
            p.paper_id, p.pwc_id, p.arxiv_id_base, p.arxiv_id_versioned, p.title,
  ...
DEBUG: SYNC fetch_side_effect received call. Query: '
        SELECT mpl.hf_model_id, p.pwc_id
        FROM model_paper_links mpl
        JOIN papers p O...', Batch: 10, Params: None
DEBUG: Mock PG _async_generator yielding 2 items for query: 
        SELECT mpl.hf_model_id, p.pwc_id
        FROM model_paper_links mpl
        JOIN papers p O...
DEBUG: Mock PG _async_generator finished yielding for query: 
        SELECT mpl.hf_model_id, p.pwc_id
        FROM model_paper_links mpl
        JOIN papers p O...
DEBUG: run_sync finished.
FAILED

=================================== FAILURES ===================================
______________________ test_run_sync_success_direct_mocks ______________________

self = <AsyncMock name='mock.save_papers_batch' id='139749617718480'>

    def assert_awaited_once(self):
        """
        Assert that the mock was awaited exactly once.
        """
        if not self.await_count == 1:
            msg = (f"Expected {self._mock_name or 'mock'} to have been awaited once."
                   f" Awaited {self.await_count} times.")
>           raise AssertionError(msg)
E           AssertionError: Expected save_papers_batch to have been awaited once. Awaited 0 times.

../../miniconda/envs/AIGraphX/lib/python3.11/unittest/mock.py:2283: AssertionError

During handling of the above exception, another exception occurred:

    @pytest.mark.asyncio
    @patch('scripts.sync_pg_to_neo4j.NEO4J_WRITE_BATCH_SIZE', NEO4J_WRITE_BATCH_SIZE_TEST)
    @patch('scripts.sync_pg_to_neo4j.PG_FETCH_BATCH_SIZE', PG_FETCH_BATCH_SIZE_TEST)
    async def test_run_sync_success_direct_mocks(
        # 不需要来自装饰器的 mock repository 参数
    ):
        """使用直接 mock 测试 run_sync 的成功执行编排。"""
    
        # --- Mock 设置 ---
        mock_pg_repo = AsyncMock(spec=PostgresRepository)
        mock_neo4j_repo = AsyncMock(spec=Neo4jRepository)
    
        # --- Mock PG 数据 --- (Keep data definitions)
        hf_models_pg_data = [
            {"hf_model_id": "hf-1", "hf_author": "auth1", "hf_sha": "sha1", "hf_last_modified": datetime(2023, 1, 1, 10, 0, 0), "hf_tags": '["tagA", "tagB"]', "hf_pipeline_tag": "text-gen", "hf_downloads": 100, "hf_likes": 10, "hf_library_name": "transformers"},
            {"hf_model_id": "hf-2", "hf_author": "auth2", "hf_sha": "sha2", "hf_last_modified": datetime(2023, 1, 2, 11, 0, 0), "hf_tags": None, "hf_pipeline_tag": "img-class", "hf_downloads": 200, "hf_likes": 20, "hf_library_name": "timm"},
            {"hf_model_id": "hf-3", "hf_author": "auth3", "hf_sha": "sha3", "hf_last_modified": datetime(2023, 1, 3, 12, 0, 0), "hf_tags": '["tagC"]', "hf_pipeline_tag": "text-gen", "hf_downloads": 50, "hf_likes": 5, "hf_library_name": "transformers"},
        ]
        papers_pg_data = [
            {"paper_id": 1, "pwc_id": "pwc-1", "arxiv_id_base": "1111.1111", "arxiv_id_versioned": "1111.1111v1", "title": "Paper 1", "authors": '["Auth1", "Auth2"]', "summary": "Summary 1", "published_date": datetime(2023, 1, 1), "area": "CV", "pwc_url": "url1", "pdf_url": "pdf1", "doi": "doi1", "primary_category": "cs.CV", "categories": '["cs.CV", "cs.AI"]'},
            {"paper_id": 2, "pwc_id": "pwc-2", "arxiv_id_base": "2222.2222", "arxiv_id_versioned": "2222.2222v1", "title": "Paper 2", "authors": None, "summary": "Summary 2", "published_date": datetime(2023, 2, 1), "area": "NLP", "pwc_url": "url2", "pdf_url": "pdf2", "doi": "doi2", "primary_category": "cs.CL", "categories": '["cs.CL"]'},
            {"paper_id": 3, "pwc_id": None, "arxiv_id_base": "3333.3333", "arxiv_id_versioned": "3333.3333v1", "title": "Paper 3 (arxiv only)", "authors": '[]', "summary": "Summary 3", "published_date": datetime(2023, 3, 1), "area": "AI", "pwc_url": None, "pdf_url": "pdf3", "doi": "doi3", "primary_category": "cs.AI", "categories": '["cs.AI"]'}
        ]
        tasks_pg_data = [{"paper_id": 1, "task_name": "Task A"}, {"paper_id": 2, "task_name": "Task B"}]
        datasets_pg_data = [{"paper_id": 1, "dataset_name": "Data X"}]
        repos_pg_data = [
            {"paper_id": 1, "url": "repo.com/1", "stars": 10, "is_official": True, "framework": "tf"},
            {"paper_id": 2, "url": "repo.com/2", "stars": 5, "is_official": False, "framework": "pt"}
        ]
        links_pg_data = [
            {"hf_model_id": "hf-1", "pwc_id": "pwc-1"},
            {"hf_model_id": "hf-2", "pwc_id": "pwc-2"},
        ]
    
        # --- 配置 Mocks ---
        # Side effect IS SYNCHRONOUS (def)
        def fetch_side_effect_sync(query: str, batch_size: int, params: Optional[tuple] = None):
            # Internal generator IS ASYNC (async def)
            async def _async_generator(data_source):
                print(f"DEBUG: Mock PG _async_generator yielding {len(data_source)} items for query: {query[:100]}...")
                if data_source:
                    for item in data_source:
                        yield item
                print(f"DEBUG: Mock PG _async_generator finished yielding for query: {query[:100]}...")
    
            print(f"DEBUG: SYNC fetch_side_effect received call. Query: '{query[:100]}...', Batch: {batch_size}, Params: {params}")
    
            # Determine data source based on query
            if "FROM hf_models" in query:
                data = hf_models_pg_data
            elif "FROM papers p" in query and "ORDER BY p.paper_id" in query:
                 data = papers_pg_data
            elif "FROM pwc_tasks" in query:
                paper_ids_param = params[0] if params and isinstance(params[0], (list, tuple)) else []
                data = [item for item in tasks_pg_data if item['paper_id'] in paper_ids_param]
            elif "FROM pwc_datasets" in query:
                paper_ids_param = params[0] if params and isinstance(params[0], (list, tuple)) else []
                data = [item for item in datasets_pg_data if item['paper_id'] in paper_ids_param]
            elif "FROM pwc_repositories" in query:
                paper_ids_param = params[0] if params and isinstance(params[0], (list, tuple)) else []
                data = [item for item in repos_pg_data if item['paper_id'] in paper_ids_param]
            elif "FROM model_paper_links" in query:
                 data = links_pg_data
            else:
                print(f"DEBUG: WARNING - Unmatched query in sync mock fetch: {query}")
                data = []
    
            # Return the async generator OBJECT directly
            return _async_generator(data)
    
        # Assign the SYNCHRONOUS side effect function
        mock_pg_repo.fetch_data_cursor.side_effect = fetch_side_effect_sync
    
        # --- 执行被测函数 ---
        print("\nDEBUG: Calling run_sync...")
        await run_sync(mock_pg_repo, mock_neo4j_repo)
        print("DEBUG: run_sync finished.")
    
        # --- 断言 --- (Keep assertions as they were in the detailed example)
        # 1. 检查 Neo4j 约束调用
        mock_neo4j_repo.create_constraints.assert_awaited_once()
    
        # 2. 断言 HF 模型被正确保存（分批）
        batch1_hf = [
            {'model_id': 'hf-1', 'author': 'auth1', 'sha': 'sha1', 'last_modified': hf_models_pg_data[0]['hf_last_modified'], 'tags': ['tagA', 'tagB'], 'pipeline_tag': 'text-gen', 'downloads': 100, 'likes': 10, 'library_name': 'transformers'},
            {'model_id': 'hf-2', 'author': 'auth2', 'sha': 'sha2', 'last_modified': hf_models_pg_data[1]['hf_last_modified'], 'tags': [], 'pipeline_tag': 'img-class', 'downloads': 200, 'likes': 20, 'library_name': 'timm'},
            {'model_id': 'hf-3', 'author': 'auth3', 'sha': 'sha3', 'last_modified': hf_models_pg_data[2]['hf_last_modified'], 'tags': ['tagC'], 'pipeline_tag': 'text-gen', 'downloads': 50, 'likes': 5, 'library_name': 'transformers'},
        ]
        mock_neo4j_repo.save_hf_models_batch.assert_awaited_once_with(batch1_hf)
    
        # 3. 断言论文被正确保存（考虑富化和拆分）
        enriched_paper_1_final = {
            'paper_id': 1, 'pwc_id': 'pwc-1', 'arxiv_id_base': '1111.1111', 'arxiv_id_versioned': '1111.1111v1', 'title': 'Paper 1', 'authors': ['Auth1', 'Auth2'], 'summary': 'Summary 1', 'published_date': '2023-01-01T00:00:00', 'area': 'CV', 'pwc_url': 'url1', 'pdf_url': 'pdf1', 'doi': 'doi1', 'primary_category': 'cs.CV', 'categories': ['cs.CV', 'cs.AI'],
            'tasks': ['Task A'],
            'datasets': ['Data X'],
            'repositories': [{'url': 'repo.com/1', "stars": 10, "is_official": True, "framework": "tf"}]
        }
        enriched_paper_2_final = {
            'paper_id': 2, 'pwc_id': 'pwc-2', 'arxiv_id_base': '2222.2222', 'arxiv_id_versioned': '2222.2222v1', 'title': 'Paper 2', 'authors': [], 'summary': 'Summary 2', 'published_date': '2023-02-01T00:00:00', 'area': 'NLP', 'pwc_url': 'url2', 'pdf_url': 'pdf2', 'doi': 'doi2', 'primary_category': 'cs.CL', 'categories': ['cs.CL'],
            'tasks': ['Task B'],
            'datasets': [],
            'repositories': [{'url': 'repo.com/2', "stars": 5, "is_official": False, "framework": "pt"}]
        }
        expected_pwc_papers_batch = [enriched_paper_1_final, enriched_paper_2_final]
        # TEMPORARY DEBUG: Check if the call was awaited at all, ignoring args for now
>       mock_neo4j_repo.save_papers_batch.assert_awaited_once()
E       AssertionError: Expected save_papers_batch to have been awaited once. Awaited 0 times.

tests/scripts/test_sync_pg_to_neo4j.py:140: AssertionError
=========================== short test summary info ============================
FAILED tests/scripts/test_sync_pg_to_neo4j.py::test_run_sync_success_direct_mocks
============================== 1 failed in 0.08s ===============================
